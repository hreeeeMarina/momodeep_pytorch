{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d001a34830>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(class=i) = \\frac{e^i}{\\sum{e^i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.FloatTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch는 softmax function을 가진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "hypothesis = func.softmax(z, dim=0)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률이기 때문에, softmax를 나온 결과를 다 더하면 1이다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss (Low-level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi-class classification에 대해서, cross entropy loss를 사용하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L=\\frac{1}{N}\\sum{-ylog(\\hat{y})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{y}$는 예측된 확률이고, y는 정답 확률이다. 0 또는 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pi 가 특정 확률에 대한 참값 또는 목표 확률이고, qi가 우리가 현재 학습한 확률값입니다. 예를 들어 여기서는 **y=[0.5, 0.125, 0.125, 0.25]** 이고, **$\\hat{y}$=[0.25, 0.25, 0.25, 0.25]** 가 되는 셈입니다. 따라서, 우리가 어떤 $\\hat{y}$ 를 학습하고 있는 상태라면 y에 가까워질수록 cross entropy 값은 작아지게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.rand(3,5)**  \n",
    "normal distribution에 따라 random변수를 3행 5열의 2D로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1664, 0.1871, 0.1737, 0.2695, 0.2033],\n",
      "        [0.2002, 0.1783, 0.2218, 0.1944, 0.2054],\n",
      "        [0.1809, 0.2380, 0.2318, 0.1084, 0.2409]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.rand(3, 5, requires_grad=True) # normal distribution에 따라 \n",
    "hypothesis = func.softmax(z, dim =1)\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.randint(5, (3, ))** = **torch.randint(범위, tensor size)**  \n",
    "0부터 4까지의 random한 정수를 뽑아서 3 vector로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randint(5, (3, )).long() # 0 ~ 4까지의 정수형태의 값을 random하게 뽑아\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = torch.Size([2, 3, 3])일 때,  \n",
    "**torch.unsqueeze(a, 0)** a의 가로로 차원을 늘림  [[2, 3, 3]]  \n",
    "**torch.unsqueeze(a, 1)** a의 세로로 차원을 늘림  \n",
    "[[2],  \n",
    " [3],  \n",
    " [3]])  \n",
    "**example)**  \n",
    "torch.unsqueeze(a,0) --> [1, 2, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[0],\n",
      "        [4],\n",
      "        [3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = torch.zeros_like(hypothesis) # hypothesis size = [3, 5]\n",
    "print(y_one_hot)\n",
    "print(y.unsqueeze(1))\n",
    "y_one_hot.scatter_(1, y.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.scatter_(1, y.unsqueeze(1), 1) = torch.scatter_(dim, index, src)**  \n",
    "dim0은 아래방향, dim =1은 오른쪽방향  \n",
    "index = y.unsqueeze(1)  \n",
    "src = index자리에 1로 바꿔치기 하고싶은 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8661, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1).mean()\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy Loss with torch.nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L=\\frac{1}{N}\\sum{-ylog(\\hat{y})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9123, -1.0210, -0.7188, -0.9835, -0.7893],\n",
       "        [-1.1317, -1.3434, -1.5274, -1.1360, -1.5699],\n",
       "        [-1.2877, -0.9707, -1.2189, -1.1878, -1.0854]], grad_fn=<LogBackward>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "torch.log(func.softmax(z, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6958, -1.5521, -1.5206, -2.0267, -1.3689],\n",
       "        [-1.4496, -1.4090, -1.8638, -1.7136, -1.6839],\n",
       "        [-1.8201, -1.2507, -1.7696, -1.9799, -1.4138]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high level\n",
    "func.log_softmax(z, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7865, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Low level\n",
    "(y_one_hot * -torch.log(func.softmax(z, dim=1))).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7865, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High level\n",
    "func.nll_loss(func.log_softmax(z, dim=1), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**func.nll_loss()**는 음수 loss likelihood를 계산하기 위한 함수!!  \n",
    "**func.cross_entropy()** 는 func.log_softmax()와 func.nll_loss()를 합친 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7865, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.cross_entropy(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Low-level Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.901535\n",
      "Epoch  200/1000 Cost: 0.839114\n",
      "Epoch  300/1000 Cost: 0.807826\n",
      "Epoch  400/1000 Cost: 0.788472\n",
      "Epoch  500/1000 Cost: 0.774822\n",
      "Epoch  600/1000 Cost: 0.764449\n",
      "Epoch  700/1000 Cost: 0.756191\n",
      "Epoch  800/1000 Cost: 0.749398\n",
      "Epoch  900/1000 Cost: 0.743671\n",
      "Epoch 1000/1000 Cost: 0.738749\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산 (1)\n",
    "    hypothesis = func.softmax(x_train.matmul(W) + b, dim=1) # or .mm or @\n",
    "    y_one_hot = torch.zeros_like(hypothesis)\n",
    "    y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "    cost = (y_one_hot * -torch.log(func.softmax(hypothesis, dim=1))).sum(dim=1).mean()\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with func.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.761050\n",
      "Epoch  200/1000 Cost: 0.689991\n",
      "Epoch  300/1000 Cost: 0.643229\n",
      "Epoch  400/1000 Cost: 0.604117\n",
      "Epoch  500/1000 Cost: 0.568255\n",
      "Epoch  600/1000 Cost: 0.533922\n",
      "Epoch  700/1000 Cost: 0.500291\n",
      "Epoch  800/1000 Cost: 0.466908\n",
      "Epoch  900/1000 Cost: 0.433507\n",
      "Epoch 1000/1000 Cost: 0.399962\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((4,3), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr = 0.1)\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    # Cost 계산 (2)\n",
    "    z = x_train.matmul(W)+b\n",
    "    cost = func.cross_entropy(z, y_train)\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Implementation with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 3) #입력이 4 ouput 3?\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/1000 Cost: 0.255025\n",
      "Epoch:  100/1000 Cost: 0.235599\n",
      "Epoch:  200/1000 Cost: 0.224077\n",
      "Epoch:  300/1000 Cost: 0.213600\n",
      "Epoch:  400/1000 Cost: 0.204023\n",
      "Epoch:  500/1000 Cost: 0.195235\n",
      "Epoch:  600/1000 Cost: 0.187144\n",
      "Epoch:  700/1000 Cost: 0.179671\n",
      "Epoch:  800/1000 Cost: 0.172750\n",
      "Epoch:  900/1000 Cost: 0.166321\n",
      "Epoch: 1000/1000 Cost: 0.160337\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr =0.1)\n",
    "\n",
    "epochs = 1000\n",
    "loss = []\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    # H(x)계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    #cost계산\n",
    "    cost = func.cross_entropy(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x)개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch: {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, epochs, cost.item()\n",
    "        ))\n",
    "    loss.append(cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss)\n",
    "plt.legend(['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(xy[:, 0:-1])\n",
    "y_train = torch.LongTensor(xy[:, [-1]]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101, 16])\n",
      "101\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 4., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 4., 1., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 4., 0., 0., 1.],\n",
      "        [1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 4., 1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) # x_train shape\n",
    "print(len(x_train))  # x_train 길이\n",
    "print(x_train[:5])   # 첫 다섯 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101])\n",
      "101\n",
      "tensor([0, 0, 3, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape) # y_train shape\n",
    "print(len(y_train))  # y_train 길이\n",
    "print(y_train[:5])   # 첫 다섯 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7\n",
    "y_one_hot = torch.zeros((len(y_train), nb_classes))\n",
    "y_one_hot = y_one_hot.scatter(1, y_train.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with func.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 1.945909\n",
      "Epoch  100/1000 Cost: 0.471836\n",
      "Epoch  200/1000 Cost: 0.326328\n",
      "Epoch  300/1000 Cost: 0.257839\n",
      "Epoch  400/1000 Cost: 0.215762\n",
      "Epoch  500/1000 Cost: 0.186603\n",
      "Epoch  600/1000 Cost: 0.164898\n",
      "Epoch  700/1000 Cost: 0.147955\n",
      "Epoch  800/1000 Cost: 0.134279\n",
      "Epoch  900/1000 Cost: 0.122962\n",
      "Epoch 1000/1000 Cost: 0.113422\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "W = torch.zeros((16, 7), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산 (2)\n",
    "    z = x_train.matmul(W) + b # or .mm or @\n",
    "    cost = func.cross_entropy(z, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level Implementation with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(16, 7)\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 2.502898\n",
      "Epoch  100/1000 Cost: 0.478620\n",
      "Epoch  200/1000 Cost: 0.325364\n",
      "Epoch  300/1000 Cost: 0.252136\n",
      "Epoch  400/1000 Cost: 0.207125\n",
      "Epoch  500/1000 Cost: 0.176217\n",
      "Epoch  600/1000 Cost: 0.153539\n",
      "Epoch  700/1000 Cost: 0.136129\n",
      "Epoch  800/1000 Cost: 0.122314\n",
      "Epoch  900/1000 Cost: 0.111072\n",
      "Epoch 1000/1000 Cost: 0.101739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = func.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
