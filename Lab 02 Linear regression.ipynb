{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requires_grad = True : 학습할 것이라고 명시\n",
    "- Weight와 Bias 0으로 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = Wx + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.mean((hypothesis-y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 한번만 ]\n",
    "1. 데이터 정의\n",
    "2. Hypothesis 초기화\n",
    "3. Optimizer 정의\n",
    "----------------------------------\n",
    "[ 반복 ]\n",
    "1. Hypothesis 예측\n",
    "2. Cost 계산\n",
    "3. Optimizer로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e978c7b890>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.],\n",
      "        [-2.],\n",
      "        [-3.]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis-y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [4.],\n",
      "        [9.]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print((hypothesis-y_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis-y_train)**2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W, b], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zero_grad() : gradient 초기화\n",
    "- backward() : gradient 계산\n",
    "- step()으로 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward(retain_graph=True)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0933], requires_grad=True)\n",
      "tensor([0.0400], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1333],\n",
      "        [0.2267],\n",
      "        [0.3200]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6927, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 W: 0.093, b: 0.040 Cost: 4.666667\n",
      "Epoch  100/1000 W: 0.873, b: 0.289 Cost: 0.012043\n",
      "Epoch  200/1000 W: 0.900, b: 0.227 Cost: 0.007442\n",
      "Epoch  300/1000 W: 0.921, b: 0.179 Cost: 0.004598\n",
      "Epoch  400/1000 W: 0.938, b: 0.140 Cost: 0.002842\n",
      "Epoch  500/1000 W: 0.951, b: 0.110 Cost: 0.001756\n",
      "Epoch  600/1000 W: 0.962, b: 0.087 Cost: 0.001085\n",
      "Epoch  700/1000 W: 0.970, b: 0.068 Cost: 0.000670\n",
      "Epoch  800/1000 W: 0.976, b: 0.054 Cost: 0.000414\n",
      "Epoch  900/1000 W: 0.981, b: 0.042 Cost: 0.000256\n",
      "Epoch 1000/1000 W: 0.985, b: 0.033 Cost: 0.000158\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level Implementation with nn. Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 linear regression 모델을 만들면 되는데, 기본적으로 PyTorch의 모든 모델은 제공되는 nn.Module을 inherit 해서 만들게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1,1) # (1,1) --> 이게 무슨의미인지 모르곘는데..\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 $__init__$에서는 사용할 레이어들을 정의하게 됩니다. 여기서 우리는 linear regression 모델을 만들기 때문에, nn.Linear 를 이용할 것입니다. 그리고 forward에서는 이 모델이 어떻게 입력값에서 출력값을 계산하는지 알려줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel() #  -> y = w * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 생성해서 예측값 $H(x)$를 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = model(x_train)  # -> y = w * x_train + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0739],\n",
      "        [0.5891],\n",
      "        [1.1044]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0739],\n",
      "        [0.5891],\n",
      "        [1.1044]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "print(hypothesis)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = torch.nn.functional.mse_loss(hypothesis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1471, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 주어진 cost를 이용해 $H(x)$ 의 $W, b$ 를 바꾸어서 cost를 줄여봅니다. 이때 PyTorch의 torch.optim 에 있는 optimizer 들 중 하나를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Full Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Linear Regression 코드를 이해했으니, 실제로 코드를 돌려 피팅시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 w:0.031, b: -0.045 Cost 5.766424\n",
      "Epoch  100/1000 w:0.890, b: 0.251 Cost 0.009079\n",
      "Epoch  200/1000 w:0.913, b: 0.197 Cost 0.005610\n",
      "Epoch  300/1000 w:0.932, b: 0.155 Cost 0.003467\n",
      "Epoch  400/1000 w:0.946, b: 0.122 Cost 0.002142\n",
      "Epoch  500/1000 w:0.958, b: 0.096 Cost 0.001324\n",
      "Epoch  600/1000 w:0.967, b: 0.075 Cost 0.000818\n",
      "Epoch  700/1000 w:0.974, b: 0.059 Cost 0.000505\n",
      "Epoch  800/1000 w:0.980, b: 0.047 Cost 0.000312\n",
      "Epoch  900/1000 w:0.984, b: 0.037 Cost 0.000193\n",
      "Epoch 1000/1000 w:0.987, b: 0.029 Cost 0.000119\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "# 모델 초기화 --> y = W * x + b\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "#optimizer 설정\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01)\n",
    "\n",
    "epochs = 1000\n",
    "loss = []\n",
    "for epoch in range(epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    \n",
    "    # cost 계산\n",
    "    cost = torch.nn.functional.mse_loss(prediction, y_train)\n",
    "    \n",
    "    # cost로 H(x)개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].item()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} w:{:.3f}, b: {:.3f} Cost {:.6f}'.format(\n",
    "            epoch, epochs, W, b, cost.item()\n",
    "        ))\n",
    "        loss.append(cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)\n",
    "plt.legend(['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
